# ğŸ›’ Tecnocomparador

Comparador de preÃ§os de produtos de tecnologia em lojas portuguesas. O sistema faz web scraping em tempo real em 6 lojas diferentes para encontrar os melhores preÃ§os.

## ğŸª Lojas Suportadas

- **Worten** - www.worten.pt
- **PCDiga** - www.pcdiga.com
- **Radio Popular** - www.radiopopular.pt
- **PCBem** - www.pcbem.pt
- **Chip7** - chip7.pt
- **GlobalData** - www.globaldata.pt

## ğŸš€ Tecnologias

- **Backend:** Node.js + Express + Puppeteer
- **Frontend:** React
- **Banco de Dados:** PostgreSQL (Supabase)
- **Web Scraping:** Puppeteer (Headless Chrome)
- **AutenticaÃ§Ã£o:** JWT

## ğŸ“ Estrutura do Projeto

```
comparador/
â”œâ”€â”€ backend/          # API Node.js
â”œâ”€â”€ frontend/         # React App
â””â”€â”€ README.md
```

## âš™ï¸ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <seu-repositorio>
cd comparador
```

### 2. Instalar dependÃªncias
```bash
npm run install-all
```

### 3. Configurar Backend
Crie o arquivo `backend/.env` baseado no `.env.example`:
```env
PORT=5000
DATABASE_URL=postgresql://postgres:[senha]@[host].supabase.com:5432/postgres
JWT_SECRET=seu_token_secreto_aqui
FRONTEND_URL=http://localhost:3000
NODE_ENV=development
```

### 4. Configurar Banco de Dados
Execute os scripts SQL em `backend/config/schema.sql`

### 5. Rodar o projeto
```bash
# Desenvolvimento (backend + frontend simultÃ¢neos)
npm run dev

# Ou separadamente:
npm run server  # Backend na porta 5000
npm run client  # Frontend na porta 3000
```

## ğŸŒ Deploy

### Banco de Dados (Supabase)
1. Criar conta em [Supabase](https://supabase.com)
2. Criar novo projeto
3. Executar `backend/config/schema.sql` no SQL Editor
4. Copiar connection string

### Backend (Render)
1. Criar conta no [Render](https://render.com)
2. Conectar repositÃ³rio GitHub
3. Configurar Web Service:
   - **Root Directory:** `backend`
   - **Build Command:** `npm install`
   - **Start Command:** `node server.js`
4. Adicionar variÃ¡veis de ambiente
5. Deploy automÃ¡tico

### Frontend (Vercel)
1. Criar conta em [Vercel](https://vercel.com)
2. Importar projeto do GitHub
3. Configurar:
   - **Framework:** Create React App
   - **Root Directory:** `frontend`
4. Adicionar variÃ¡vel: `REACT_APP_API_URL`
5. Deploy automÃ¡tico

## ğŸ“‹ Funcionalidades

- âœ… Busca em tempo real com web scraping (Puppeteer)
- âœ… ComparaÃ§Ã£o de preÃ§os em 6 lojas portuguesas
- âœ… PaginaÃ§Ã£o automÃ¡tica (atÃ© 5 pÃ¡ginas por loja)
- âœ… Sistema de favoritos (requer login)
- âœ… PreÃ§os em euros (â‚¬)
- âœ… ExibiÃ§Ã£o de descontos e preÃ§os originais
- âœ… OrdenaÃ§Ã£o por preÃ§o e nome
- âœ… Interface moderna e responsiva
- âœ… AutenticaÃ§Ã£o com JWT

## ğŸ”— Endpoints API

### AutenticaÃ§Ã£o
- `POST /api/auth/register` - Criar conta
- `POST /api/auth/login` - Login

### Busca
- `GET /api/buscar?termo=produto` - Buscar em todas as lojas

### Favoritos
- `GET /api/favoritos` - Listar favoritos do usuÃ¡rio
- `POST /api/favoritos` - Adicionar favorito
- `DELETE /api/favoritos/:id` - Remover favorito
- `DELETE /api/favoritos/produto/:produto_id` - Remover por produto

## âš™ï¸ Como Funciona o Web Scraping

O sistema utiliza **Puppeteer** (Headless Chrome) para fazer scraping em tempo real:

1. UsuÃ¡rio faz uma busca (ex: "notebook")
2. Backend inicia 6 scrapers em paralelo (Promise.all)
3. Cada scraper:
   - Acessa a loja com o termo de busca
   - Extrai produtos da pÃ¡gina 1
   - Clica em "prÃ³xima pÃ¡gina" e repete (atÃ© 5 pÃ¡ginas)
   - Remove duplicados
4. Resultados sÃ£o agregados e retornados ao frontend
5. Produtos favoritos sÃ£o salvos automaticamente no banco

### âš ï¸ LimitaÃ§Ãµes do Puppeteer em Ambientes Serverless

**Problema:** O Render (plano gratuito) nÃ£o inclui Chromium por padrÃ£o, fazendo o scraping falhar.

**SoluÃ§Ã£o Implementada:**
- Em **produÃ§Ã£o**: Usa `@sparticuz/chromium` (Chromium otimizado para serverless)
- Em **desenvolvimento**: Usa o Puppeteer normal com Chrome local

**ConfiguraÃ§Ã£o no cÃ³digo:**
```javascript
// backend/services/puppeteer-scraper.js
const isProd = process.env.NODE_ENV === 'production';

if (isProd) {
  // Chromium otimizado para Render/Lambda
  browser = await puppeteer.launch({
    args: chromium.args,
    executablePath: await chromium.executablePath()
  });
} else {
  // Puppeteer normal para desenvolvimento
  browser = await puppeteer.launch({ headless: true });
}
```

**DependÃªncias necessÃ¡rias:**
```bash
npm install @sparticuz/chromium puppeteer-core
```

**Alternativas se o scraping continuar lento:**
- Migrar para plano pago do Render ($7/mÃªs)
- Usar Railway ou Fly.io (melhor suporte a Puppeteer)
- Implementar cache de resultados
- Usar APIs oficiais das lojas (se disponÃ­veis)

## ğŸ“ LicenÃ§a

MIT
