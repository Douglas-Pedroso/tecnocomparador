# ğŸ›’ Tecnocomparador

Comparador de preÃ§os de produtos de tecnologia em lojas portuguesas. O sistema faz web scraping em tempo real em 6 lojas diferentes para encontrar os melhores preÃ§os.

## ğŸª Lojas Suportadas

- **Worten** - www.worten.pt
- **PCDiga** - www.pcdiga.com
- **Radio Popular** - www.radiopopular.pt
- **PCBem** - www.pcbem.pt
- **Chip7** - chip7.pt
- **GlobalData** - www.globaldata.pt

## ğŸš€ Tecnologias

- **Backend:** Node.js + Express + Puppeteer
- **Frontend:** React
- **Banco de Dados:** PostgreSQL (Supabase)
- **Web Scraping:** Puppeteer (Headless Chrome)
- **AutenticaÃ§Ã£o:** JWT

## ğŸ“ Estrutura do Projeto

```
comparador/
â”œâ”€â”€ backend/          # API Node.js
â”œâ”€â”€ frontend/         # React App
â””â”€â”€ README.md
```

## âš™ï¸ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone <seu-repositorio>
cd comparador
```

### 2. Instalar dependÃªncias
```bash
npm run install-all
```

### 3. Configurar Backend
Crie o arquivo `backend/.env` baseado no `.env.example`:
```env
PORT=5000
DATABASE_URL=postgresql://postgres:[senha]@[host].supabase.com:5432/postgres
JWT_SECRET=seu_token_secreto_aqui
FRONTEND_URL=http://localhost:3000
NODE_ENV=development
```

### 4. Configurar Banco de Dados
Execute os scripts SQL em `backend/config/schema.sql`

### 5. Rodar o projeto
```bash
# Desenvolvimento (backend + frontend simultÃ¢neos)
npm run dev

# Ou separadamente:
npm run server  # Backend na porta 5000
npm run client  # Frontend na porta 3000
```

## ğŸŒ Deploy

### Banco de Dados (Supabase)
1. Criar conta em [Supabase](https://supabase.com)
2. Criar novo projeto
3. Executar `backend/config/schema.sql` no SQL Editor
4. Copiar connection string

### Backend (Render)
1. Criar conta no [Render](https://render.com)
2. Conectar repositÃ³rio GitHub
3. Configurar Web Service:
   - **Root Directory:** `backend`
   - **Build Command:** `npm install`
   - **Start Command:** `node server.js`
4. Adicionar variÃ¡veis de ambiente
5. Deploy automÃ¡tico

### Frontend (Vercel)
1. Criar conta em [Vercel](https://vercel.com)
2. Importar projeto do GitHub
3. Configurar:
   - **Framework:** Create React App
   - **Root Directory:** `frontend`
4. Adicionar variÃ¡vel: `REACT_APP_API_URL`
5. Deploy automÃ¡tico

## ğŸ“‹ Funcionalidades

- âœ… Busca em tempo real com web scraping (Puppeteer)
- âœ… ComparaÃ§Ã£o de preÃ§os em 6 lojas portuguesas
- âœ… PaginaÃ§Ã£o automÃ¡tica (atÃ© 5 pÃ¡ginas por loja)
- âœ… Sistema de favoritos (requer login)
- âœ… PreÃ§os em euros (â‚¬)
- âœ… ExibiÃ§Ã£o de descontos e preÃ§os originais
- âœ… OrdenaÃ§Ã£o por preÃ§o e nome
- âœ… Interface moderna e responsiva
- âœ… AutenticaÃ§Ã£o com JWT

## ğŸ”— Endpoints API

### AutenticaÃ§Ã£o
- `POST /api/auth/register` - Criar conta
- `POST /api/auth/login` - Login

### Busca
- `GET /api/buscar?termo=produto` - Buscar em todas as lojas

### Favoritos
- `GET /api/favoritos` - Listar favoritos do usuÃ¡rio
- `POST /api/favoritos` - Adicionar favorito
- `DELETE /api/favoritos/:id` - Remover favorito
- `DELETE /api/favoritos/produto/:produto_id` - Remover por produto

## âš™ï¸ Como Funciona o Web Scraping

O sistema utiliza **Puppeteer** (Headless Chrome) para fazer scraping em tempo real:

1. UsuÃ¡rio faz uma busca (ex: "notebook")
2. Backend inicia 6 scrapers em paralelo (Promise.all)
3. Cada scraper:
   - Acessa a loja com o termo de busca
   - Extrai produtos da pÃ¡gina 1
   - Clica em "prÃ³xima pÃ¡gina" e repete (atÃ© 5 pÃ¡ginas)
   - Remove duplicados
4. Resultados sÃ£o agregados e retornados ao frontend
5. Produtos favoritos sÃ£o salvos automaticamente no banco

## ğŸ› Problemas Encontrados e SoluÃ§Ãµes

### 1ï¸âƒ£ Web Scraping Falha no Render Free Tier

**âŒ Problema:**
O Render (plano gratuito com 512MB RAM) nÃ£o consegue rodar Puppeteer/Chromium:
- Chromium precisa de 100-200MB RAM
- Node.js + Express usa 50-100MB RAM
- Total: >250MB (quase 50% da RAM disponÃ­vel)
- Resultado: Browser nunca inicializa, scrapers retornam vazio

**Tentativas que NÃƒO funcionaram:**
- âœ— Usar `@sparticuz/chromium` (versÃ£o otimizada)
- âœ— Usar `puppeteer-core` em vez de `puppeteer`
- âœ— Adicionar args: `--single-process`, `--disable-dev-shm-usage`
- âœ— Todos falharam devido Ã  limitaÃ§Ã£o de RAM

**âœ… SoluÃ§Ã£o Implementada: Sistema de Cache**

Em vez de fazer scraping em tempo real no servidor, implementamos:

1. **Script local** (`backend/scrape-and-save.js`):
   - Roda no seu computador (tem RAM suficiente)
   - Faz scraping das 6 lojas
   - Salva produtos no Supabase (PostgreSQL na nuvem)

2. **Backend em produÃ§Ã£o** (`routes/produtos.js`):
   - Consulta produtos do banco em vez de fazer scraping
   - Filtra produtos atualizados nos Ãºltimos 7 dias
   - Se banco vazio, usa dados mock como fallback

**Como usar:**
```bash
# Executar manualmente quando quiser atualizar
cd backend
node scrape-and-save.js "notebook"
node scrape-and-save.js "telemÃ³vel"
node scrape-and-save.js "tablet"

# Agendar no Windows (Task Scheduler)
# Ver instruÃ§Ãµes em backend/ATUALIZACAO-AUTOMATICA.md
```

**Vantagens:**
- âœ… 100% gratuito
- âœ… Dados reais das lojas
- âœ… Servidor rÃ¡pido (sÃ³ consulta DB)
- âœ… Pode atualizar quantas vezes quiser

**Desvantagens:**
- âš ï¸ Dados nÃ£o sÃ£o em tempo real (atualizaÃ§Ã£o manual ou agendada)
- âš ï¸ Precisa rodar script periodicamente

**ConfiguraÃ§Ã£o no cÃ³digo:**
```javascript
// backend/services/puppeteer-scraper.js
const isProd = process.env.NODE_ENV === 'production';

if (isProd) {
  // ProduÃ§Ã£o: Chromium otimizado (ainda falha no Render Free)
  const puppeteerCore = require('puppeteer-core');
  const chromium = require('@sparticuz/chromium');
  browser = await puppeteerCore.launch({
    args: chromium.args,
    executablePath: await chromium.executablePath()
  });
} else {
  // Desenvolvimento: Puppeteer normal (funciona)
  const puppeteer = require('puppeteer');
  browser = await puppeteer.launch({ headless: true });
}
```

### 2ï¸âƒ£ Produtos Duplicados no Banco de Dados

**âŒ Problema:**
ApÃ³s rodar o script mÃºltiplas vezes, produtos apareciam duplicados:
- Mesmo produto 13x vezes (exemplo: "ASUS TUF Gaming...")
- Causa 1: Dados MOCK sendo salvos (id_externo: `mock_chip7_...`)
- Causa 2: Mesmo nome com IDs externos diferentes

**âœ… SoluÃ§Ã£o:**

1. **Remover dados mock do banco:**
```bash
node backend/limpar-mock.js
# Removeu 102 produtos mock
```

2. **Remover duplicatas por nome:**
```bash
node backend/limpar-nomes-duplicados.js
# Removeu 3.365 duplicatas, mantendo a versÃ£o mais recente
```

3. **Prevenir novos duplicados:**
```javascript
// backend/scrape-and-save.js
// Filtra produtos mock antes de salvar
const produtosReais = produtos.filter(p => 
  p.id_externo && !p.id_externo.startsWith('mock_')
);
```

4. **Query de busca com DISTINCT:**
```sql
-- Backend consulta produtos Ãºnicos por nome e loja
SELECT * FROM produtos 
WHERE LOWER(nome) LIKE LOWER('%notebook%')
AND atualizado_em > NOW() - INTERVAL '7 days'
ORDER BY loja, preco ASC
```

**Resultado:**
- âœ… De 4.450 produtos â†’ 983 produtos Ãºnicos
- âœ… Sem duplicatas visuais no frontend
- âœ… Dados limpos e organizados

### 3ï¸âƒ£ Scripts de ManutenÃ§Ã£o

Criados para resolver problemas acima:

```bash
# Limpar dados mock
node backend/limpar-mock.js

# Remover duplicatas por id_externo + loja
node backend/limpar-duplicatas.js

# Remover duplicatas por nome + loja
node backend/limpar-nomes-duplicados.js

# Verificar duplicatas
node backend/verificar-duplicatas.js

# Testar conexÃ£o com banco
node backend/test-banco.js
```

**DocumentaÃ§Ã£o completa:** Ver `backend/ATUALIZACAO-AUTOMATICA.md`

## ğŸ“ LicenÃ§a

MIT
